---
title: "Estimation of sampling effort in community ecology with SSP"
author: "Edlin Guerra-Castro, Juan Carlos Cajas, Juan Jose Cruz-Motta, Nuno Simoes and Maite Mascaro"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
        
vignette: >
  %\VignetteIndexEntry{Estimation of sampling effort in community ecology with SSP}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
library(SSP)
library(ggplot2)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.retina=2,
  fig.align='center',
  fig.width = 7, 
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)
```

`SSP` is an R package design to estimate sample effort in studies of ecological communities based on the definition of pseudo multivariate standard error (*MultSE*) (Anderson & Santana-Garcon 2015). This guide will provide you a brief overview in how to use `SSP`. The theoretical background are described in a submitted paper by Guerra-Castro et al. (2019).

The protocol in `SSP` consists in simulating several extensive data matrices that mimic some of the relevant ecological features of the community of interest using a pilot data set. For each simulated data, several sampling efforts are repeatedly executed and *MultSE* is calculated to each one. The mean value, 0.025 and 0.975 quantiles of *MultSE* for each sampling effort across all simulated data are then estimated, and potentially plotted using `ggplot2`. The mean values are then standardized regarding the lowest sampling effort (consequently, the worst precision), and an optimal sampling effort can be identified as that in which the increase in sampling effort do not improve the precision beyond a threshold value (e.g. 1 %).

`SSP` include six functions: `assempar` for extrapolation of assemblage parameters using pilot data; `simdata` for simulation of several data sets based on extrapolated parameters; `datquality` for evaluation of plausibility of simulated data; `sampsd` for repeated estimations of *MultSE* for different sampling designs in simulated data sets; `summary_sd` for summarizing  the behavior of *MultSE* for each sampling design across all simulated data sets, and `ioptimum` for identification of the optimal sampling effort.

## PACKAGE NEEDED IN SSP
- Required: `vegan`, `sampling`, `stats` [R](https://cran.r-project.org/)
- Suggested: `ggplot2` [R](https://cran.r-project.org/)
- Also `devtools`, `httr` to build SSP from [github](https://github.com/edlinguerra/SSP)

## HOW TO RUN SSP:
The `SSP` package will be available on [CRAN](https://cran.r-project.org/) but can be downloaded from github using the following commands:  

```{r eval=FALSE}
## install SSP package from CRAN
install.packages("SSP")

## install the latest version from github
install.packages('devtools')
library(devtools)
install_github('edlinguerra/SSP')

## import packages
library(SSP)
library(ggplot2)
```

## FUNCTIONS AND SEQUENCE

The first function to use is `assempar`. The arguments of this functions are:

<table style="width:100%;">
<colgroup>
<col width="20%">
<col width="80%">
</colgroup>
<thead>
<tr class="header">
<th align="center">Argument</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>data</code></td>
<td align="left">a <code>data.frame</code> with species names (columns) and samples (rows) information. The first column should indicate the site to which the sample belongs, regardless of whether a single site has been sampled.</td>
</tr>
<tr class="even">
<td align="center"><code>type</code></td>
<td align="left">Nature of the data to be processed. It may be presence / absence ("P/A"), counts of individuals ("counts"), or coverage ("cover").</td>
</tr>
<tr class="odd">
<td align="center"><code>Sest.method</code></td>
<td align="left">Method for estimating species richness. The function function <code>specpool</code> is used for this. Available methods are the incidence-based Chao "chao", first order jackknife "jack1", second order jackknife "jack2" and Bootstrap "boot". By default, the "average" of the four estimates is used.</td>
</tr>

</tbody>
</table>

This function extracts the main parameters of the pilot data using basic R functions as well as functions like `specpool` and `dispweight`. The expected number of species in the assemblage is estimated using non-parametric methods (Gotelli et al. 2011). Due to the variability in the estimates of each approximation (Reese et al. 2014), we recommend using an average of these. The probability detection of each species is estimated among and within sites. The former is calculated as the frequency of occurrences of each of the species against the number of sites sampled, the second as the weighted average frequencies in sites where the species were present. Also, the degree of spatial aggregation of species (only for real counts of individuals), is identified with the index of dispersion D (Clarke et al. 2006). The corresponding properties of unseen species are approximated using information of observed species. Specifically, the probabilities of detection are assumed to be equal to the rarest species of pilot data. The mean (and variance) of the abundances are defined using random poisson values with lambda as the overall mean of species abundances. `assempar`	returns an object of class `list`, to be used by `simdata`.

The second function to use is `simdata`, with the following arguments:

<table style="width:100%;">
<colgroup>
<col width="20%">
<col width="80%">
</colgroup>
<thead>
<tr class="header">
<th align="center">Argument</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>Par</code></td>
<td align="left">a <code>list</code> of parameters estimated by <code>assempar</code>.</td>
</tr>
<tr class="even">
<td align="center"><code>cases</code></td>
<td align="left">Number of data sets to be simulated.</td>
</tr>
<tr class="odd">
<td align="center"><code>n</code></td>
<td align="left">Total number of samples to simulate in each site.</td>
</tr>
<tr class="even">
<td align="center"><code>sites</code></td>
<td align="left">Total number of sites to simulate in each data set.</td>
</tr>

</tbody>
</table>

The presence/absence of each species at each site are simulated with Bernoulli trials and probability of success equals to the empirical frequency of occurrence of each species among sites in the pilot data. For sites with the presence of the species, Bernoulli trials are used, with a probability of success equal to the estimated empirical frequency within the sites where it appears, to simulate the distribution of the species at that site. Once created, the P/A matrixes are converted to matrixes of abundances replacing presences by random values from an adequate statistical distribution and parameters equals to those estimated in the pilot data. Counts of individuals were generated using Poisson or negative binomial distributions, depending on the degree of aggregation of each species in the pilot data (McArdle & Anderson 2004; Anderson & Walsh 2013). When abundances were measured as a continuous variable (i.e. coverage, biomass), they are generated using the lognormal distribution. The simulation procedure is repeated to generate as many simulated data matrixes as needed. This function returns an object of class `list` that will be used by `sampsd` and `datquality`.

The third function is `sampsd`. If several sites had been generated (multi.site = TRUE), subsets of sites of size 2 to p.s are sampled, followed by the selection of sampling units (from 2 to p.n) using inclusion probabilities and self-weighted two-stage sampling (Tille, 2011). Each combination of sampling effort (number of sample units and sites), are repeated several times (e.g. k = 100) for all simulated matrixes. If simulated data correspond to a single site (multi.site = FALSE), sampling without replacement is performed several times (e.g. k = 100) for each sample size (from 2 to p.n) within each simulated matrix. This approach is computationally intensive, especially when k is high. Keep this in mind because it will affect the time to get results. For each sample, suitable pre-treatments are applied and distance/similarity matrixes estimated using the appropriate coefficient. When simulations were done for a single site, the MultSE is estimated as \eqn{\sqrtV/n}, being V the pseudo variance measured at each sample of size n (Anderson & Santana-Garcon, 2015). When several sites were generated, MultSE are estimated using the residual mean squares and the sites mean squares from a PERMANOVA model (Anderson & Santana-Garcon, 2015). The arguments of this function:

<table style="width:100%;">
<colgroup>
<col width="20%">
<col width="80%">
</colgroup>
<thead>
<tr class="header">
<th align="center">Argument</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>dat.sim</code></td>
<td align="left">a <code>list</code> of data sets generated by <code>simdata</code></td>
</tr>
<tr class="even">
<td align="center"><code>Par</code></td>
<td align="left">a <code>list</code> of parameters estimated by <code>assempar</code></td>
</tr>
<tr class="odd">
<td align="center"><code>transformation</code></td>
<td align="left">Mathematical function to reduce the weight of very dominant species: 'square root', 'fourth root', 'Log (X+1)', 'P/A', 'none'</td>
</tr>
<tr class="even">
<td align="center"><code>method</code></td>
<td align="left">The appropiate distance/dissimilarity metric. The function <code>vegdist</code> is call for that purpose</td>
</tr>
<tr class="odd">
<td align="center"><code>multi.site</code></td>
<td align="left">Logical argument indicating if several sites were simulated</td>
</tr>
<tr class="even">
<td align="center"><code>n</code></td>
<td align="left">Total number of samples simulated for each site</td>
</tr>
<tr class="odd">
<td align="center"><code>p.n</code></td>
<td align="left">Maxinum number of samples to take at each site. Can be equal or less than n</td>
</tr>
<tr class="even">
<td align="center"><code>sites</code></td>
<td align="left">Total number of sites to simulate in each data set.</td>
</tr>
<tr class="odd">
<td align="center"><code>p.s</code></td>
<td align="left">Maxinum number of sites to sample at each data set</td>
</tr>
<tr class="even">
<td align="center"><code>k</code></td>
<td align="left">TNumber of repetitions of each combination between n and sites</td>
</tr>

</tbody>
</table>

After the sampling proceadure and estimation of *MultSE*, `summary_ssp` is requiered to estimate the mean of *MultSe* of all k repetitions within each simulated data, and then an overall mean as well as the lower and upper intervals of means for each sample size among all simulated data. In order to have a general and comparable criteria to evaluate the rate of change of the averaged *MultSE* with respect to the sampling effort, a relativization to the maximum *MultSE* value (obteined with the lower sampling effort) is calculated; then, a standard forward finite derivation is computed. All this results are presented ina data frame, that can be used to plot MultSE with respect to the sampling effort. The arguments of this function are:


<table style="width:100%;">
<colgroup>
<col width="20%">
<col width="80%">
</colgroup>
<thead>
<tr class="header">
<th align="center">Argument</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>results</code></td>
<td align="left">a <code>matrix</code> generated by <code>sampsd</code></td>
</tr>
<tr class="even">
<td align="center"><code>multi.site</code></td>
<td align="left">Logical argument indicating whether several sites were simulated</td>
</tr>

</tbody>
</table>

The fifth function, `ioptimum` estimates what we consider the optimal sampling effort. The function identifies three cut-off points on the derivative (as the percentage improvement in accuracy with respect to the highest MM per sample unit), allowing to identify the minimum required sampling effort, sub-optimal sampling effort, optimal effort and unnecessary effort. The arguments are:

<table style="width:100%;">
<colgroup>
<col width="20%">
<col width="80%">
</colgroup>
<thead>
<tr class="header">
<th align="center">Argument</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>xx</code></td>
<td align="left">a <code>data frame</code> generated by <code>summary_ssp</code></td>
</tr>
<tr class="even">
<td align="center"><code>multi.site</code></td>
<td align="left">Logical argument indicating whether several sites were simulated</td>
</tr>

</tbody>
</table>

## Performance of SSP with real data
 
**Micromollusks of marine shallow sandy bottoms**: Presence/absence of 67 species were registered in six cores of 4-inch diameter and 10 cm depth taken in sandy bottoms around Cayo Nuevo, Gulf of Mexico, Mexico (a small reef cay located 240 km off the North-Western coast of Yucatan). Data correspond to a study on the biodiversity of marine benthic reef habitats off the Yucatan shelf (Ortigosa, Suarez-Mozo, Barrera et al. 2018). The main objective was to estimate an adequate sampling effort for further quantitative studies to characterize the variability in species composition. To do this, the pilot data was characterized with `assempar` and several matrices of P/A data were simulated with `simdata`. To speed up the process, only 10 data sets (*cases*) were simulated, each data matrix consisted in 50 potential sampling replicates in one site. Various sample size’s subsets (*n* = 2 to 50) were repeatedly sampled (*k* = 10) with `sampsd`. The Jaccard index was used as the similarity measure between sample units. Keep in mind that you can simulate many more matrices (*cases*), potential number of samples (*n*), and sampling repetitions (*k*), as long as you have the time and patience to wait for the results!

```{r, eval = TRUE}
data(micromollusk)

#Estimation of parameters
par.mic<-assempar(data = micromollusk, type = "P/A")

#Simulation of data
sim.mic<-simdata(Par = par.mic, cases = 10, n = 50, site = 1)

#Sampling and estimation of MultSE
samp.mic<-sampsd(sim.mic, par.mic,
                        transformation = "P/A",
                        method = "jaccard",
                        multi.site = FALSE,
                        n=50,
                        p.n = 50,
                        sites = 1,
                        p.s = 1,
                        k=10)

#Summarizing results
sum.mic<-summary_ssp(results = samp.mic, multi.site = FALSE)

#Identification of optimal effort

opt.mic<-ioptimum(xx = sum.mic, multi.site = FALSE, c1=5, c2=3, c3=1)

```

The behavior of *MultSE* for each sampling effort on simulated data sets can be plotted using `ggplot2` (Fig. 1). The shaded area indicates the range of samples in which each increase in the sampling effort provides between 5% and 1% improvement in precision; we call this area the **optimal effort**. Beyond 17 samples, the effort does not improve more than 1 % the higher *MultSE*, which can be considered as a redundant effort. 

```{r, eval = TRUE}
fig.mic<-ggplot(sum.mic, aes(x=samples, y=mean))+
  geom_point(size = 0.5)+
  geom_errorbar(aes(ymin=lower, ymax=upper), size=0.1, width=.2)+
  theme_bw(base_size=16) +
  ylab ("Multivariate pseudo SE")+ 
  xlab("Sampling effort (n)")+
  scale_y_continuous(breaks=seq(0.0, 0.4, 0.025))+
  scale_x_continuous(breaks=seq(2, 50, 2))+
  theme(axis.text.x = element_text(colour="black", size=rel(0.7)),
        axis.text.y = element_text(colour="black", size=rel(0.7)),
        axis.title.x = element_text(colour="black", size=rel(0.9)),
        axis.title.y = element_text(colour="black", size=rel(0.9)),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(size=0.4),
        axis.ticks= element_line(size=0.2))+
  annotate("rect", xmin=opt.mic[2], xmax=opt.mic[3], ymin=min(sum.mic$lower), ymax=max(sum.mic$upper), alpha=.1, fill="blue")+
  annotate("text", x=12,  y =max(sum.mic$mean), label = "Optimal effort", fontface = "bold", size = 3 )
fig.mic 
```

```{r, echo= FALSE}

knitr::opts_chunk$set(
  fig.cap = "MultSE for micromollusk data"
)
```


## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))

## References

-Anderson

-Clarke, K. R., Chapman, M. G., Somerfield, P. J., & Needham, H. R. (2006). Dispersion-based weighting of species counts in assemblage analyses. Journal of Experimental Marine Biology and Ecology, 320, 11-27.

-Gotelli, N. J., & Colwell, R. K. (2011). Estimating species richness. Pages 39– 54 in A Magurranand B McGill editors. Biological diversity: frontiers in measurement and assessment. Oxford University Press, Oxford, UK.

-Reese, G. C., Wilson, K. R., & Flather, C. H. (2014). Performance of species richness estimators across assemblage types and survey parameters. Global Ecology and Biogeography, 23(5), 585-594.
